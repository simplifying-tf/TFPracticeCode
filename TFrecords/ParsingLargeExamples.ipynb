{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ParsingLargeExamples.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSKaUX_45jEz"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import IPython.display as display\n",
        "import tqdm\n",
        "import glob"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HKCMdrT5ydG"
      },
      "source": [
        "# The following functions can be used to convert a value to a type compatible\n",
        "# with tf.train.Example.\n",
        "\n",
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def serialize_array(array):\n",
        "  array = tf.io.serialize_tensor(array)\n",
        "  return array"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juJNEQSj-7W2"
      },
      "source": [
        "def parse_single_image(image, label):\n",
        "  \n",
        "  #define the dictionary -- the structure -- of our single example\n",
        "  data = {\n",
        "        'height' : _int64_feature(image.shape[0]),\n",
        "        'width' : _int64_feature(image.shape[1]),\n",
        "        'depth' : _int64_feature(image.shape[2]),\n",
        "        'raw_image' : _bytes_feature(serialize_array(image)),\n",
        "        'label' : _int64_feature(label)\n",
        "    }\n",
        "  #create an Example, wrapping the single features\n",
        "  return tf.train.Example(features=tf.train.Features(feature=data))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNfVKdEd54g8"
      },
      "source": [
        "# Creating Large Dataset\n",
        "Consider sharding our data across multiple such files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRVpthvi52eM"
      },
      "source": [
        "image_large_shape = (400,750,3)\n",
        "number_of_images_large = 500 #constraining to 500 files here, to not outgrow RAM capacities\n",
        "\n",
        "images_large = np.random.randint(low=0, high=256, size=(number_of_images_large, *image_large_shape), dtype=np.int16)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuKmYVzE6JAs"
      },
      "source": [
        "labels_large = np.random.randint(low=0, high=5, size=(number_of_images_large, 1))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_k9Nfqp6Oyc"
      },
      "source": [
        "\n",
        "def write_images_to_tfr_long(images, labels, filename:str=\"large_images\", max_files:int=10, out_dir:str=\"/content/\"):\n",
        "\n",
        "  #determine the number of shards (single TFRecord files) we need:\n",
        "  splits = (len(images)//max_files) + 1 #determine how many tfr shards are needed\n",
        "  if len(images)%max_files == 0:\n",
        "    splits-=1\n",
        "  print(f\"\\nUsing {splits} shard(s) for {len(images)} files, with up to {max_files} samples per shard\")\n",
        "\n",
        "  file_count = 0\n",
        "\n",
        "  for i in tqdm.tqdm(range(splits)):\n",
        "    current_shard_name = \"{}{}_{}{}.tfrecords\".format(out_dir, i+1, splits, filename)\n",
        "    writer = tf.io.TFRecordWriter(current_shard_name)\n",
        "\n",
        "    current_shard_count = 0\n",
        "    while current_shard_count < max_files: #as long as our shard is not full\n",
        "      #get the index of the file that we want to parse now\n",
        "      index = i*max_files+current_shard_count\n",
        "      if index == len(images): #when we have consumed the whole data, preempt generation\n",
        "        break\n",
        "\n",
        "      current_image = images[index]\n",
        "      current_label = labels[index]\n",
        "\n",
        "        \n",
        "      out = parse_single_image(image=current_image, label=current_label)\n",
        "      \n",
        "      writer.write(out.SerializeToString())\n",
        "      current_shard_count+=1\n",
        "      file_count += 1\n",
        "\n",
        "    writer.close()\n",
        "  print(f\"\\nWrote {file_count} elements to TFRecord\")\n",
        "  # return file_count"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxJgDjSN8W1s",
        "outputId": "b0c4448e-8dfa-4c09-8cf0-f0e1440cd836"
      },
      "source": [
        "write_images_to_tfr_long(images_large, labels_large, max_files=30)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using 17 shard(s) for 500 files, with up to 30 samples per shard\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 17/17 [00:03<00:00,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Wrote 500 elements to TFRecord\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8DrL6pIA4bh"
      },
      "source": [
        "def parse_tfr_element(element):\n",
        "  #use the same structure as above; it's kinda an outline of the structure we now want to create\n",
        "  data = {\n",
        "      'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "      'width':tf.io.FixedLenFeature([], tf.int64),\n",
        "      'label':tf.io.FixedLenFeature([], tf.int64),\n",
        "      'raw_image' : tf.io.FixedLenFeature([], tf.string),\n",
        "      'depth':tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "\n",
        "    \n",
        "  content = tf.io.parse_single_example(element, data)\n",
        "  \n",
        "  height = content['height']\n",
        "  width = content['width']\n",
        "  depth = content['depth']\n",
        "  label = content['label']\n",
        "  raw_image = content['raw_image']\n",
        "  \n",
        "  \n",
        "  #get our 'feature'-- our image -- and reshape it appropriately\n",
        "  feature = tf.io.parse_tensor(raw_image, out_type=tf.int16)\n",
        "  feature = tf.reshape(feature, shape=[height,width,depth])\n",
        "  return (feature, label)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY-PpAHwAbtX"
      },
      "source": [
        "def get_dataset_large(tfr_dir:str=\"/content/\", pattern:str=\"*large_images.tfrecords\"):\n",
        "    files = glob.glob(tfr_dir+pattern, recursive=False)\n",
        "\n",
        "    #create the dataset\n",
        "    dataset = tf.data.TFRecordDataset(files)\n",
        "\n",
        "    #pass every single feature through our mapping function\n",
        "    dataset = dataset.map(\n",
        "        parse_tfr_element\n",
        "    )\n",
        "    \n",
        "    return dataset"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HNI_l3eA6_k",
        "outputId": "f353c081-eb12-44b4-c75d-ab8d46a96393"
      },
      "source": [
        "\n",
        "dataset_large = get_dataset_large()\n",
        "\n",
        "for sample in dataset_large.take(1):\n",
        "  print(sample[0].shape)\n",
        "  print(sample[1].shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(400, 750, 3)\n",
            "()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D2AIPjtA-LM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}